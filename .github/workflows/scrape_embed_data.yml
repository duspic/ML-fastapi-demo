name: scrape_and_embed_job_data

on:
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * *" # 6 AM UTC daily

jobs:
  run_data_pipeline:
    runs-on: ubuntu-latest
    steps:

      - name: Checkout code
        uses: actions/checkout@v4
        with: 
          token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.10.14
          cache: "pip"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Scrape LinkedIn data
        run: python3 scripts/scrape.py --keywords Python Software Developer AI  --locations Zagreb Remote

      - name: Embed scraped data
        run: python3 scripts/embed_job_data.py

      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v6
        with:
          token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          title: "CRON JOB - Data update"
          body: |
            Automatic cron job for the data pipeline - check how many jobs are scraped before merging!
          branch: "automated-daily-update"
          base: "main"
          delete-branch: true
